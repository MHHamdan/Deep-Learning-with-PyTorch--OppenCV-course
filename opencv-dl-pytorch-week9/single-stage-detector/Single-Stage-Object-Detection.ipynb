{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Single Stage Object Detection</font>\n",
    "\n",
    "As it was previously discussed, there are two types of object detectors: single-stage and two-stage. The latter was invented earlier and is much slower in training.\n",
    "\n",
    "In the section, we will discuss the following:\n",
    "1. Single-stage NN-Architecture,\n",
    "\n",
    "2. How to generate anchor-boxes,\n",
    "\n",
    "3. How to match prediction with ground truth,\n",
    "\n",
    "4. The loss function of object detector, and\n",
    "\n",
    "5. The training pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">1. Detector NN-Architecture</font>\n",
    "\n",
    "Single-stage object detection network pipeline looks like as follows:\n",
    "\n",
    "---\n",
    "\n",
    "<img src='https://www.learnopencv.com/wp-content/uploads/2020/03/c3-w8-pipeline.png' align=\"middle\">\n",
    "\n",
    "---\n",
    "\n",
    "- In our implementation, feature extractor is the combination of `ResNet-18` and `FPN` ([Feature Pyramid Network](https://arxiv.org/pdf/1612.03144.pdf)).\n",
    "\n",
    "\n",
    "- After feature extraction, we have two predictor networks- one for class prediction and other for bounding box prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1.1. ResNet</font>\n",
    "\n",
    "- We will use a pre-trained ResNet-18 model. \n",
    "\n",
    "\n",
    "- In object detection, it is always recommended to use a pre-trained model for feature extraction and train the model to solve the detection problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1.2. Feature Pyramid Network (FPN)</font>\n",
    "\n",
    "- Extracting the features from different convolution layers performs better than using only the last convolution layer. \n",
    "\n",
    "\n",
    "- `FPN` ([Feature Pyramid Network](https://arxiv.org/pdf/1612.03144.pdf)). is a network that extracts features from different layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1.3. Class and Box Subnet</font>\n",
    "\n",
    "- We have two predictor network- one for class prediction and other for bounding box prediction that uses extracted features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">2. Generating Anchor Boxes</font>\n",
    "\n",
    "**What is an anchor?**\n",
    "\n",
    "Our feature extractor is the combination of `ResNet-18` and `FPN`. We get convolution feature of dimensions $[num_{channel}, height, width]$ from the feature extractor. The feature maps correspond to the position $[:, i, j]$ $\\forall$ $i$ & $j$, use to have different bounding boxes (of different sizes and aspect ratios assuming this position is the center of the bounding box) associated with it. This predefined bounding box is called an anchor. \n",
    "\n",
    "How this anchor is being generated, we will see in the coming unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">3. Matching Predictions with Ground Truth</font>\n",
    "\n",
    "We are predicting bounding boxes and class for each bounding box for every feature map, where we have few bounding boxes and class of the bounding boxes in our original image input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3.1. Encoding Boxes</font>\n",
    "\n",
    "In training (to find the loss), we need the target dimension to be the same as the network prediction dimension to calculate the loss. So we need some sort of encoding to our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3.2. Decoding Boxes</font>\n",
    "\n",
    "We will have to decode the bounding box prediction of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">4. Loss Function</font>\n",
    "\n",
    "We need a special loss function to solve object detection problems, for example, Online Hard Example Mining (OHEM), focal loss, etc.\n",
    "\n",
    "We will see the loss function details in the coming unit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">5. Experiment (Training)</font>\n",
    "\n",
    "We will use the trainer pipeline to train our detection network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
