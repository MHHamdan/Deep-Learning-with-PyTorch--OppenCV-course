{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Inference on Production<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Lightning-Module\" data-toc-modified-id=\"Lightning-Module-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Lightning Module</a></span></li><li><span><a href=\"#Get-the-Checkpoint\" data-toc-modified-id=\"Get-the-Checkpoint-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Get the Checkpoint</a></span></li><li><span><a href=\"#Convert-to-ONNX-Format\" data-toc-modified-id=\"Convert-to-ONNX-Format-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Convert to ONNX Format</a></span></li><li><span><a href=\"#Sample-Inference\" data-toc-modified-id=\"Sample-Inference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sample Inference</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assume your team is working on a project where you need to work on some ML problems. \n",
    "2. What if you pick one issue and solve it with the help of the PyTorch framework while your colleague does the same, using Tensorflow. \n",
    "3. Both problems we know are part of a bigger project. Now, how to arrive at a common format to share the ML models.\n",
    "\n",
    "\n",
    "<a target=\"_blank\" href=\"https://onnx.ai/\">ONNX: Open Neural Network Exchange</a> is one such open format that allows model interchange between various <a target=\"_blank\" href=\"https://onnx.ai/supported-tools\">ML frameworks and tools</a>.\n",
    "\n",
    "\n",
    "**In this notebook, we will see how to convert a PyTorch Lightning saved checkpoint to the ONNX model.  Let's take the example of the checkpoint saved by the notebook on MNIST training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import AverageMeter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # filter UserWarning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning Module\n",
    "\n",
    "The Lighting module gives us the model definition to load a model from checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(pl.LightningModule):  # here nn.Module is replaced by LightningModule\n",
    "    def __init__(self, learning_rate=0.01, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # Save the arguments as hyperparameters.\n",
    "        self.save_hyperparameters()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (28, 28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2-d\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # Second convolution layer\n",
    "            # input size = (14, 14), output size = (10, 10)\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (5, 5)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120),\n",
    "\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # Third fully connected layer. It is also the output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            nn.Linear(in_features=84, out_features=self.num_classes))\n",
    "\n",
    "        acc_obj = Accuracy(num_classes=self.num_classes)\n",
    "        # use .clone() so that each metric can maintain its own state\n",
    "        self.train_acc = acc_obj.clone()\n",
    "        self.valid_acc = acc_obj.clone()\n",
    "\n",
    "        # Using average meter to accumulate losses and get mean of the metrics\n",
    "        average_meter = AverageMeter()\n",
    "        self.train_loss = average_meter.clone()\n",
    "        self.valid_loss = average_meter.clone()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weights_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        super().on_train_epoch_start()\n",
    "\n",
    "        # Reset state variables for train metrics to \n",
    "        # their default values before start of each epoch\n",
    "    \n",
    "        self.train_acc.reset()\n",
    "        self.train_loss.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        super().on_validation_epoch_start()\n",
    "        \n",
    "        # Reset state variables for validation metrics to \n",
    "        # their default values before start of each epoch\n",
    "        \n",
    "        self.valid_acc.reset()\n",
    "        self.valid_loss.reset()\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # get data and labels from batch\n",
    "        data, target = batch\n",
    "\n",
    "        # get prediction\n",
    "        output = self(data)\n",
    "\n",
    "        # calculate batch loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "\n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]\n",
    "\n",
    "        # Using Module API\n",
    "        # calculate and accumulate batch accuracy\n",
    "        acc = self.train_acc(pred, target)\n",
    "\n",
    "        # accumulate batch loss\n",
    "        self.train_loss(loss)\n",
    "        # # -----------------\n",
    "\n",
    "        # LOG METRICS to a logger. Default: Tensorboard\n",
    "        self.log(\"train/batch_loss\", loss, prog_bar=False)\n",
    "\n",
    "        # logging and adding current batch_acc to progress_bar\n",
    "        self.log(\"train/batch_acc\", acc, prog_bar=True)\n",
    "\n",
    "        # Using Module API, we only need to return the loss\n",
    "        return loss\n",
    "       \n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        # Using Module API\n",
    "        # Compute epoch loss and accuracy\n",
    "        avg_train_loss = self.train_loss.compute()\n",
    "        avg_train_acc = self.train_acc.compute()\n",
    "        # # -----------------\n",
    "\n",
    "        self.log(\"train/loss\", avg_train_loss, prog_bar=True)\n",
    "        self.log(\"train/acc\", avg_train_acc, prog_bar=True)\n",
    "        # Set X-axis as epoch number for epoch-level metrics\n",
    "        self.log(\"step\", self.current_epoch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        # get data and labels from batch\n",
    "        data, target = batch\n",
    "\n",
    "        # get prediction\n",
    "        output = self(data)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "\n",
    "        # get the index of the max probability\n",
    "        pred = torch.argmax(prob, dim=1)\n",
    "        \n",
    "        # Using Module API\n",
    "        # accumulate validation accuracy and loss\n",
    "        self.valid_acc(pred, target)\n",
    "        self.valid_loss(loss)\n",
    "        \n",
    "        \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        # Using Module API\n",
    "        avg_val_loss = self.valid_loss.compute()\n",
    "        avg_val_acc = self.valid_acc.compute()\n",
    "        \n",
    "        self.log(\"valid/acc\", avg_val_acc, prog_bar=True)\n",
    "        self.log(\"valid/loss\", avg_val_loss, prog_bar=True)\n",
    "        # use epoch as X-axis\n",
    "        self.log(\"step\", self.current_epoch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(),\n",
    "                               lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Checkpoint\n",
    "\n",
    "We are going to load one of the checkpoints saved during the last training.\n",
    "\n",
    "We have written a helper function for it. It takes the log directory of PyTorch Lighting training and runs the version number to return the corresponding `.ckpt` path.\n",
    "\n",
    "Youâ€™ll be familiar with  this function from the last unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_latest_run_version_ckpt_epoch_no(lightning_logs_dir='lightning_logs', run_version=None):\n",
    "    if run_version is None:\n",
    "        run_version = 0\n",
    "        for dir_name in os.listdir(lightning_logs_dir):\n",
    "            if 'version' in dir_name:\n",
    "                if int(dir_name.split('_')[1]) > run_version:\n",
    "                    run_version = int(dir_name.split('_')[1])\n",
    "                \n",
    "    checkpoints_dir = os.path.join(lightning_logs_dir, 'version_{}'.format(run_version), 'checkpoints')\n",
    "    \n",
    "    files = os.listdir(checkpoints_dir)\n",
    "    ckpt_filename = None\n",
    "    for file in files:\n",
    "        if file.endswith('.ckpt'):\n",
    "            ckpt_filename = file\n",
    "        \n",
    "    if ckpt_filename is not None:\n",
    "        ckpt_path = os.path.join(checkpoints_dir, ckpt_filename)\n",
    "    else:\n",
    "        print('CKPT file is not present')\n",
    "    \n",
    "    return ckpt_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us get the `.ckpt` model path.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt_path: lightning_logs\\version_0\\checkpoints\\epoch=1-step=469.ckpt\n"
     ]
    }
   ],
   "source": [
    "# get checkpoint path\n",
    "ckpt_path = get_latest_run_version_ckpt_epoch_no(run_version=0)\n",
    "print('ckpt_path: {}'.format(ckpt_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to ONNX Format\n",
    "\n",
    "We have written a function to convert `.ckpt` model to `.onnx` model. \n",
    "\n",
    "The function takes the model definition, `.ckpt` path, and the `.onnx` file path as arguments. And convert the `.ckpt` file to `.onnx` and return the `.onnx` path. \n",
    "\n",
    "We find an `input_sample` being  used with `.ckpt` to `.onnx` conversion method `to_onnx`. This sample input fixes the input size, binding us to use the same  at the time of inference.\n",
    "\n",
    "Get details <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "def convert_to_onnx_model(model, ckpt_path, onnx_path=None):\n",
    "    \n",
    "    # ONNX filename\n",
    "    if onnx_path is None:\n",
    "        onnx_path = ckpt_path[:-4] + 'onnx'\n",
    "        \n",
    "    # Load the checkpoint\n",
    "    ckpt_model = model.load_from_checkpoint(ckpt_path)\n",
    "    \n",
    "    # Freeze the network\n",
    "    ckpt_model.freeze()\n",
    "    \n",
    "    ckpt_model.eval()\n",
    "    \n",
    "    # Add a sample input. Here input shape = (batch_size, num_channel, height, width)\n",
    "    input_sample = torch.randn((1, 1, 32, 32))\n",
    "    \n",
    "    # convert to ONNX model\n",
    "    ckpt_model.to_onnx(onnx_path, input_sample, export_params=True)\n",
    "    \n",
    "    return onnx_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us convert `.ckpt` to `.onnx`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx_model_path: lightning_logs\\version_0\\checkpoints\\epoch=1-step=469.onnx\n"
     ]
    }
   ],
   "source": [
    "# initiate the model\n",
    "model = LeNet5()\n",
    "\n",
    "# convert the checkpoint to onnx format\n",
    "onnx_model_path = convert_to_onnx_model(model, ckpt_path)\n",
    "print('onnx_model_path: {}'.format(onnx_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Inference\n",
    "\n",
    "**Steps for the inference with `.onnx` model:**\n",
    "\n",
    "- Init the session. This is a one-time operation.\n",
    "\n",
    "\n",
    "- Get the input name from the session. Again, one-time operation.\n",
    "\n",
    "\n",
    "- Prepare input. \n",
    "\n",
    "\n",
    "- Run the session with the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.08154127, -0.0619623 , -0.1705806 ,  0.08606329,  0.02861519,\n",
      "        -0.06603519,  0.0394491 ,  0.05756365, -0.0192312 ,  0.0117478 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# init a session\n",
    "sess = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# get input name from session\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "# prepare inputs\n",
    "inputs = {input_name: np.random.randn(1, 1, 32, 32).astype(np.float32)}\n",
    "\n",
    "# get output\n",
    "outputs = sess.run(None, inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "1. <a target=\"_blank\" href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html\">https://pytorch-lightning.readthedocs.io/en/stable/common/production_inference.html</a>\n",
    "2. <a target=\"_blank\" href=\"https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model\">https://docs.microsoft.com/en-us/windows/ai/windows-ml/get-onnx-model</a>\n",
    "3. <a target=\"_blank\" href=\"https://onnx.ai/\">https://onnx.ai/</a>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu]",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Inference on Production",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
