{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Trainer Class</font>\n",
    "\n",
    "**This is a generic class for training loop.**\n",
    "\n",
    "Trainer class is equivalent to the `main` method. \n",
    "\n",
    "In the main method, we were passing configurations, the model, optimizer, learning rate scheduler, and the number of epochs.  It was calling the method to get the train and test data loader. Using these, it is training and validating the model. During training and validation, it was also sending logs to TensorBoard and saving the model.\n",
    "\n",
    "The trainer class is doing the same in a more modular way so that we can experiment with different loss functions, different visualizers, different types of targets, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Unified class to make training pipeline for deep neural networks.\"\"\"\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable\n",
    "from pathlib import Path\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .hooks import test_hook_default, train_hook_default\n",
    "from .visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Trainer Class Methods and its Parameters</font>\n",
    "\n",
    "### <font style=\"color:green\">  \\_\\_init\\_\\_ </font>\n",
    "\n",
    "Setting different attributes.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `model` : `nn.Module` - torch model to train\n",
    "\n",
    "        \n",
    "- `loader_train` : `torch.utils.DataLoader` - train dataset loader.\n",
    "\n",
    "    \n",
    "- `loader_test` : `torch.utils.DataLoader` - test dataset loader\n",
    "\n",
    "       \n",
    "- `loss_fn` : `callable` - loss function. In the main function, the cross-entropy loss was being used; here, we can pass the loss we want to use. For example, if we are solving a regression problem, we can not use cross-entropy loss. It is better to use RMS-loss.\n",
    "\n",
    "\n",
    "        \n",
    "- `metric_fn` : `callable` - evaluation metric function. In the main function, we had loss and accuracy as our evaluation metric. Here we can pass any evaluation metric. For example, in a detection problem, we need a precision-recall metric instead of accuracy.\n",
    "\n",
    "        \n",
    "- `optimizer` : `torch.optim.Optimizer` - Optimizer.\n",
    "\n",
    "        \n",
    "- `lr_scheduler` : `torch.optim.LrScheduler` - Learning Rate scheduler.\n",
    "\n",
    "        \n",
    "- `configuration` : `TrainerConfiguration` - a set of training process parameters.\n",
    "\n",
    "Here, we need a data iterator and target iterator separately, because we are writing a general trainer class. For example, for the detection problem for a single image, we might have `n`-number of objects and their coordinates. \n",
    "\n",
    "        \n",
    "- `data_getter` : `Callable` - function object to extract input data from the sample prepared by dataloader.\n",
    "\n",
    "        \n",
    "- `target_getter` : `Callable` - function object to extract target data from the sample prepared by dataloader.\n",
    "\n",
    "        \n",
    "- `visualizer` : `Visualizer` - optional, shows metrics values (various backends are possible). We can pass the visualizer of our choice. For example, Matplotlib based visualizer, TensorBoard based, etc.\n",
    "\n",
    "It is also calling its method `_register_default_hooks` what this method does we will see next. In short, this is making sure that training and validation function is registered at the time of trainer class object initiation. \n",
    "\n",
    "\n",
    "### <font style=\"color:green\"> _register_default_hooks </font>\n",
    "\n",
    "It is calling the another method `register_hook` to register training (`train_hook_default`) and validation (`test_hook_default`) functions. `train_hook_default` and `test_hook_default` are defined in the `hook`-module.  We will go in details in the module.\n",
    "\n",
    "\n",
    "### <font style=\"color:green\"> register_hook </font>\n",
    "\n",
    "It is updating the key-value pair of a dictionary, where the key is string and value is a callable function.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `hook_type`: `string` - hook type. For example, wether the function will be used for train or test.\n",
    "\n",
    "\n",
    "- `hook_fn`: `callable` - hook function.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### <font style=\"color:green\"> fit </font>\n",
    "\n",
    "Taking the number of epochs and training and validating the model. It is also adding logs to the visualizer. \n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `epochs`: `int` - number of epochs to train model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:  # pylint: disable=too-many-instance-attributes\n",
    "    \"\"\" Generic class for training loop.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        torch model to train\n",
    "    loader_train : torch.utils.DataLoader\n",
    "        train dataset loader.\n",
    "    loader_test : torch.utils.DataLoader\n",
    "        test dataset loader\n",
    "    loss_fn : callable\n",
    "        loss function\n",
    "    metric_fn : callable\n",
    "        evaluation metric function\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimizer\n",
    "    lr_scheduler : torch.optim.LrScheduler\n",
    "        Learning Rate scheduler\n",
    "    configuration : TrainerConfiguration\n",
    "        a set of training process parameters\n",
    "    data_getter : Callable\n",
    "        function object to extract input data from the sample prepared by dataloader.\n",
    "    target_getter : Callable\n",
    "        function object to extract target data from the sample prepared by dataloader.\n",
    "    visualizer : Visualizer, optional\n",
    "        shows metrics values (various backends are possible)\n",
    "    # \"\"\"\n",
    "    def __init__( # pylint: disable=too-many-arguments\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        loader_train: torch.utils.data.DataLoader,\n",
    "        loader_test: torch.utils.data.DataLoader,\n",
    "        loss_fn: Callable,\n",
    "        metric_fn: Callable,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        lr_scheduler: Callable,\n",
    "        device: Union[torch.device, str] = \"cuda\",\n",
    "        model_saving_frequency: int = 1,\n",
    "        save_dir: Union[str, Path] = \"checkpoints\",\n",
    "        model_name_prefix: str = \"model\",\n",
    "        data_getter: Callable = itemgetter(\"image\"),\n",
    "        target_getter: Callable = itemgetter(\"target\"),\n",
    "        stage_progress: bool = True,\n",
    "        visualizer: Union[Visualizer, None] = None,\n",
    "        get_key_metric: Callable = itemgetter(\"top1\"),\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.loader_train = loader_train\n",
    "        self.loader_test = loader_test\n",
    "        self.loss_fn = loss_fn\n",
    "        self.metric_fn = metric_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.model_saving_frequency = model_saving_frequency\n",
    "        self.save_dir = save_dir\n",
    "        self.model_name_prefix = model_name_prefix\n",
    "        self.stage_progress = stage_progress\n",
    "        self.data_getter = data_getter\n",
    "        self.target_getter = target_getter\n",
    "        self.hooks = {}\n",
    "        self.visualizer = visualizer\n",
    "        self.get_key_metric = get_key_metric\n",
    "        self.metrics = {\"epoch\": [], \"train_loss\": [], \"test_loss\": [], \"test_metric\": []}\n",
    "        self._register_default_hooks()\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        \"\"\" Fit model method.\n",
    "\n",
    "        Arguments:\n",
    "            epochs (int): number of epochs to train model.\n",
    "        \"\"\"\n",
    "        iterator = tqdm(range(epochs), dynamic_ncols=True)\n",
    "        for epoch in iterator:\n",
    "            output_train = self.hooks[\"train\"](\n",
    "                self.model,\n",
    "                self.loader_train,\n",
    "                self.loss_fn,\n",
    "                self.optimizer,\n",
    "                self.device,\n",
    "                prefix=\"[{}/{}]\".format(epoch, epochs),\n",
    "                stage_progress=self.stage_progress,\n",
    "                data_getter=self.data_getter,\n",
    "                target_getter=self.target_getter\n",
    "            )\n",
    "            output_test = self.hooks[\"test\"](\n",
    "                self.model,\n",
    "                self.loader_test,\n",
    "                self.loss_fn,\n",
    "                self.metric_fn,\n",
    "                self.device,\n",
    "                prefix=\"[{}/{}]\".format(epoch, epochs),\n",
    "                stage_progress=self.stage_progress,\n",
    "                data_getter=self.data_getter,\n",
    "                target_getter=self.target_getter,\n",
    "                get_key_metric=self.get_key_metric\n",
    "            )\n",
    "            if self.visualizer:\n",
    "                self.visualizer.update_charts(\n",
    "                    None, output_train['loss'], output_test['metric'], output_test['loss'],\n",
    "                    self.optimizer.param_groups[0]['lr'], epoch\n",
    "                )\n",
    "\n",
    "            self.metrics['epoch'].append(epoch)\n",
    "            self.metrics['train_loss'].append(output_train['loss'])\n",
    "            self.metrics['test_loss'].append(output_test['loss'])\n",
    "            self.metrics['test_metric'].append(output_test['metric'])\n",
    "\n",
    "            if self.lr_scheduler is not None:\n",
    "                if isinstance(self.lr_scheduler, ReduceLROnPlateau):\n",
    "                    self.lr_scheduler.step(output_train['loss'])\n",
    "                else:\n",
    "                    self.lr_scheduler.step()\n",
    "\n",
    "            if self.hooks[\"end_epoch\"] is not None:\n",
    "                self.hooks[\"end_epoch\"](iterator, epoch, output_train, output_test)\n",
    "\n",
    "            if (epoch + 1) % self.model_saving_frequency == 0:\n",
    "                os.makedirs(self.save_dir, exist_ok=True)\n",
    "                torch.save(\n",
    "                    self.model.state_dict(),\n",
    "                    os.path.join(self.save_dir, self.model_name_prefix) + str(datetime.datetime.now())\n",
    "                )\n",
    "        return self.metrics\n",
    "\n",
    "    def register_hook(self, hook_type, hook_fn):\n",
    "        \"\"\" Register hook method.\n",
    "\n",
    "        Arguments:\n",
    "            hook_type (string): hook type.\n",
    "            hook_fn (callable): hook function.\n",
    "        \"\"\"\n",
    "        self.hooks[hook_type] = hook_fn\n",
    "\n",
    "    def _register_default_hooks(self):\n",
    "        self.register_hook(\"train\", train_hook_default)\n",
    "        self.register_hook(\"test\", test_hook_default)\n",
    "        self.register_hook(\"end_epoch\", None)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:light,ipynb",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
