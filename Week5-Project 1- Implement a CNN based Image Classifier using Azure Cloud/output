ssh://mhamdan@172.24.50.21:22/home/mhamdan/anaconda3/bin/python3 -u /home/mhamdan/hamdan/TrainingPipeline/trainer/full_code_ResNet_for_catsdogspandas.py
['Preprocess_data.py', 'training', 'validation']
['dog', 'cat', 'panda']
GPU  running
cuda
ResNet9(
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (res1): Sequential(
    (0): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv4): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (res2): Sequential(
    (0): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Flatten()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=512, out_features=3, bias=True)
  )
)
[{'val_loss': 1.1056809425354004, 'val_acc': 0.3333333432674408}]
Epoch [0], last_lr: 0.00008, train_loss: 0.9571, val_loss: 0.8252, val_acc: 0.6433
Epoch [1], last_lr: 0.00020, train_loss: 0.8201, val_loss: 0.6503, val_acc: 0.7217
Epoch [2], last_lr: 0.00037, train_loss: 0.7634, val_loss: 0.8077, val_acc: 0.6900
Epoch [3], last_lr: 0.00057, train_loss: 0.7641, val_loss: 0.7456, val_acc: 0.6867
Epoch [4], last_lr: 0.00076, train_loss: 0.7439, val_loss: 0.6631, val_acc: 0.6983
Epoch [5], last_lr: 0.00091, train_loss: 0.7074, val_loss: 0.6485, val_acc: 0.7467
Epoch [6], last_lr: 0.00099, train_loss: 0.6432, val_loss: 0.6630, val_acc: 0.7500
Epoch [7], last_lr: 0.00100, train_loss: 0.6824, val_loss: 0.5246, val_acc: 0.7850
Epoch [8], last_lr: 0.00098, train_loss: 0.6118, val_loss: 0.7370, val_acc: 0.7300
Epoch [9], last_lr: 0.00095, train_loss: 0.5582, val_loss: 0.5839, val_acc: 0.7800
Epoch [10], last_lr: 0.00090, train_loss: 0.5480, val_loss: 0.5020, val_acc: 0.8033
Epoch [11], last_lr: 0.00085, train_loss: 0.5008, val_loss: 0.5406, val_acc: 0.7817
Epoch [12], last_lr: 0.00078, train_loss: 0.4442, val_loss: 0.5514, val_acc: 0.7967
Epoch [13], last_lr: 0.00070, train_loss: 0.3726, val_loss: 0.5129, val_acc: 0.8067
Epoch [14], last_lr: 0.00061, train_loss: 0.3500, val_loss: 0.4462, val_acc: 0.8033
Epoch [15], last_lr: 0.00052, train_loss: 0.3038, val_loss: 0.4236, val_acc: 0.8417
Epoch [16], last_lr: 0.00043, train_loss: 0.2879, val_loss: 0.4046, val_acc: 0.8417
Epoch [17], last_lr: 0.00035, train_loss: 0.2068, val_loss: 0.4159, val_acc: 0.8500
Epoch [18], last_lr: 0.00026, train_loss: 0.1725, val_loss: 0.4060, val_acc: 0.8517
Epoch [19], last_lr: 0.00019, train_loss: 0.1226, val_loss: 0.4135, val_acc: 0.8533
Epoch [20], last_lr: 0.00012, train_loss: 0.0967, val_loss: 0.4292, val_acc: 0.8483
Epoch [21], last_lr: 0.00007, train_loss: 0.0740, val_loss: 0.4175, val_acc: 0.8600
Epoch [22], last_lr: 0.00003, train_loss: 0.0610, val_loss: 0.4473, val_acc: 0.8550
Epoch [23], last_lr: 0.00001, train_loss: 0.0595, val_loss: 0.4410, val_acc: 0.8483
Epoch [24], last_lr: 0.00000, train_loss: 0.0469, val_loss: 0.4353, val_acc: 0.8550
--- 136.0376214981079 seconds ---
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: cat , Predicted: cat
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: dog , Predicted: dog
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: panda , Predicted: panda
model-1609455689
tensor([[166.,  32.,   2.],
        [ 40., 157.,   3.],
        [  2.,   8., 190.]])

Process finished with exit code 0
ssh://mhamdan@172.24.50.21:22/home/mhamdan/anaconda3/bin/python3 -u /home/mhamdan/hamdan/TrainingPipeline/trainer/full_code_ResNet_for_catsdogspandas.py
['Preprocess_data.py', 'training', 'validation']
['dog', 'cat', 'panda']
GPU  running
cuda
ResNet9(
  (conv1): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): Sequential(
    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (res1): Sequential(
    (0): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (conv3): Sequential(
    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv4): Sequential(
    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (res2): Sequential(
    (0): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (1): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Flatten()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=512, out_features=3, bias=True)
  )
)
[{'val_loss': 1.1056809425354004, 'val_acc': 0.3333333432674408}]
Epoch [0], last_lr: 0.00008, train_loss: 0.9571, val_loss: 0.8252, val_acc: 0.6433
Epoch [1], last_lr: 0.00020, train_loss: 0.8201, val_loss: 0.6503, val_acc: 0.7217
Epoch [2], last_lr: 0.00037, train_loss: 0.7634, val_loss: 0.8077, val_acc: 0.6900
Epoch [3], last_lr: 0.00057, train_loss: 0.7641, val_loss: 0.7456, val_acc: 0.6867
Epoch [4], last_lr: 0.00076, train_loss: 0.7439, val_loss: 0.6631, val_acc: 0.6983
Epoch [5], last_lr: 0.00091, train_loss: 0.7074, val_loss: 0.6485, val_acc: 0.7467
Epoch [6], last_lr: 0.00099, train_loss: 0.6432, val_loss: 0.6630, val_acc: 0.7500
Epoch [7], last_lr: 0.00100, train_loss: 0.6824, val_loss: 0.5246, val_acc: 0.7850
Epoch [8], last_lr: 0.00098, train_loss: 0.6118, val_loss: 0.7370, val_acc: 0.7300
Epoch [9], last_lr: 0.00095, train_loss: 0.5582, val_loss: 0.5839, val_acc: 0.7800
Epoch [10], last_lr: 0.00090, train_loss: 0.5480, val_loss: 0.5020, val_acc: 0.8033
Epoch [11], last_lr: 0.00085, train_loss: 0.5008, val_loss: 0.5406, val_acc: 0.7817
Epoch [12], last_lr: 0.00078, train_loss: 0.4442, val_loss: 0.5514, val_acc: 0.7967
Epoch [13], last_lr: 0.00070, train_loss: 0.3726, val_loss: 0.5129, val_acc: 0.8067
Epoch [14], last_lr: 0.00061, train_loss: 0.3500, val_loss: 0.4462, val_acc: 0.8033
Epoch [15], last_lr: 0.00052, train_loss: 0.3038, val_loss: 0.4236, val_acc: 0.8417
Epoch [16], last_lr: 0.00043, train_loss: 0.2879, val_loss: 0.4046, val_acc: 0.8417
Epoch [17], last_lr: 0.00035, train_loss: 0.2068, val_loss: 0.4159, val_acc: 0.8500
Epoch [18], last_lr: 0.00026, train_loss: 0.1725, val_loss: 0.4060, val_acc: 0.8517
Epoch [19], last_lr: 0.00019, train_loss: 0.1226, val_loss: 0.4135, val_acc: 0.8533
Epoch [20], last_lr: 0.00012, train_loss: 0.0967, val_loss: 0.4292, val_acc: 0.8483
Epoch [21], last_lr: 0.00007, train_loss: 0.0740, val_loss: 0.4175, val_acc: 0.8600
Epoch [22], last_lr: 0.00003, train_loss: 0.0610, val_loss: 0.4473, val_acc: 0.8550
Epoch [23], last_lr: 0.00001, train_loss: 0.0595, val_loss: 0.4410, val_acc: 0.8483
Epoch [24], last_lr: 0.00000, train_loss: 0.0469, val_loss: 0.4353, val_acc: 0.8550
--- 136.0376214981079 seconds ---
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: cat , Predicted: cat
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: dog , Predicted: dog
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Label: panda , Predicted: panda
model-1609455689
tensor([[166.,  32.,   2.],
        [ 40., 157.,   3.],
        [  2.,   8., 190.]])

Process finished with exit code 0
