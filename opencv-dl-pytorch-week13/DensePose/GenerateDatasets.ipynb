{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Generate Sample Dataset for Despose Training</font>\n",
    "\n",
    "Here, we downloaded 2014 val Images from <a href=\"http://cocodataset.org/#download\">COCO website</a>. We have chosen val images (`6GB`) instead of train images (`13GB`) as it is smaller in size.\n",
    "\n",
    "**[Download the COCO val2014 Dataset](http://images.cocodataset.org/zips/val2014.zip)**\n",
    "\n",
    "After downloading the COCO val2014 dataset, unzip it in the current directory. \n",
    "\n",
    "And the annotation files can be downloaded from <a href=\"https://github.com/facebookresearch/DensePose/blob/master/DensePoseData/get_DensePose_COCO.sh\">here</a>. Let's download the annotation file by running the code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download(url, filepath):\n",
    "    response = urllib.request.urlretrieve(url, filepath)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the annotations file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('densepose_coco_2014_minival.json',\n",
       " <http.client.HTTPMessage at 0x7f5394cf2050>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "densepose_coco_2014_minival_url = 'https://dl.fbaipublicfiles.com/densepose/densepose_coco_2014_minival.json'\n",
    "annotations_path = 'densepose_coco_2014_minival.json'\n",
    "\n",
    "download(densepose_coco_2014_minival_url, annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the annotations, it is found the number of images with annotations from val set are 1500. From these images, we will use 1000 images for creating train, val and test datasets.\n",
    "\n",
    "Train, val and test datasets will follow the structure given in the detectron2 training module.\n",
    "\n",
    "```\n",
    "datasets\n",
    "|\n",
    "|-->coco\n",
    "       |\n",
    "       |-->annotations\n",
    "       |       |-->densepose_train2014.json\n",
    "       |       |-->densepose_valminusminival2014.json\n",
    "       |       |-->densepose_minival2014.json\n",
    "       |\n",
    "       |-->train2014\n",
    "       |\n",
    "       |-->val2014\n",
    "```\n",
    "\n",
    "**The following code cell prepares a dataset of `1000` images. If you want to experiment with more number of images, you can increase the number of images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 3075\n",
      "100 441\n",
      "100 394\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "src_folder = 'val2014'\n",
    "dest_folder = os.path.join('datasets', 'coco')\n",
    "dest_annotations_folder = os.path.join(dest_folder, 'annotations')\n",
    "train_dataset = os.path.join(dest_folder, 'train2014')\n",
    "val_dataset = os.path.join(dest_folder, 'val2014')\n",
    "\n",
    "#Number of images to be selected, you can increse this number, if you want to experiments with images.\n",
    "num_images = 1000\n",
    "\n",
    "os.makedirs(dest_annotations_folder, exist_ok=True)\n",
    "os.makedirs(train_dataset, exist_ok=True)\n",
    "os.makedirs(val_dataset, exist_ok=True)\n",
    "\n",
    "with open(annotations_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "count = 0\n",
    "train_image_ids = []\n",
    "test_image_ids = []\n",
    "val_image_ids = []\n",
    "\n",
    "for im in random.sample(data[\"images\"], num_images):\n",
    "    img_name = im['file_name']\n",
    "    img_id =  str(im['id'])\n",
    "\n",
    "    if count%5 == 0:\n",
    "        img_path = os.path.join(src_folder, img_name)\n",
    "        shutil.copy(img_path, val_dataset)\n",
    "\n",
    "        if count%10 == 0:\n",
    "            test_image_ids.append(img_id)\n",
    "        else:\n",
    "            val_image_ids.append(img_id)\n",
    "    else:\n",
    "        shutil.copy(img_path, train_dataset)\n",
    "        train_image_ids.append(img_id)\n",
    "\n",
    "    count = count + 1\n",
    "\n",
    "train_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "val_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "test_data = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "\n",
    "for im_obj in data[\"images\"]:\n",
    "    if str(im_obj[\"id\"]) in train_image_ids:\n",
    "        train_data[\"images\"].append(im_obj)\n",
    "\n",
    "    if str(im_obj[\"id\"]) in val_image_ids:\n",
    "        val_data[\"images\"].append(im_obj)\n",
    "\n",
    "    if str(im_obj[\"id\"]) in test_image_ids:\n",
    "        test_data[\"images\"].append(im_obj)\n",
    "\n",
    "for ann_obj in data[\"annotations\"]:\n",
    "    if str(ann_obj[\"image_id\"]) in train_image_ids:\n",
    "        train_data[\"annotations\"].append(ann_obj)\n",
    "\n",
    "    if str(ann_obj[\"image_id\"]) in val_image_ids:\n",
    "        val_data[\"annotations\"].append(ann_obj)\n",
    "\n",
    "    if str(ann_obj[\"image_id\"]) in test_image_ids:\n",
    "        test_data[\"annotations\"].append(ann_obj)\n",
    "\n",
    "train_data[\"categories\"] = data[\"categories\"]\n",
    "test_data[\"categories\"] = data[\"categories\"]\n",
    "val_data[\"categories\"] = data[\"categories\"]\n",
    "\n",
    "with open(os.path.join(dest_annotations_folder,\"densepose_train2014.json\"), \"w\") as  f:\n",
    "    f.write(json.dumps(train_data))\n",
    "\n",
    "with open(os.path.join(dest_annotations_folder,\"densepose_valminusminival2014.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(val_data))\n",
    "\n",
    "with open(os.path.join(dest_annotations_folder,\"densepose_minival2014.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(test_data))\n",
    "\n",
    "print(len(train_data[\"images\"]), len(train_data[\"annotations\"]))\n",
    "print(len(val_data[\"images\"]), len(val_data[\"annotations\"]))\n",
    "print(len(test_data[\"images\"]), len(test_data[\"annotations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
