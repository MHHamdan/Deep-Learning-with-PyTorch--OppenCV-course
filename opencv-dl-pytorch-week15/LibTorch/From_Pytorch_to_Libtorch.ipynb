{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color='blue'> Pytorch to Libtorch</font>\n",
    "\n",
    "In the previous section, we saw how Pytorch allows us to create an Intermediate-Representation of a network, with an idea of loading and inferring this `IR` over a different language.   \n",
    "And this is where `Libtorch` comes up.  \n",
    "\n",
    "In fact, converting the model to an `IR` is just a few lines of code.  \n",
    "And it involves almost the stuff we discussed in the previous notebook.\n",
    "\n",
    "Let's take a look as to how we can do this. \n",
    "\n",
    "First, we create a simple model `LeNet` in Pytorch and pass it inside the `torch.jit.script()` to get the `IR`. \n",
    "Once we get this `IR` of `LeNet`, we can save it as a `.pt` file so that it can be loaded within `Libtorch`.  \n",
    "Then, we just need to load the file using `torch::jit::load(\"*.pt\")`.\n",
    "\n",
    "\n",
    "One thing to note is that in PyTorch, we used to have the model saved with only the `model-parameters ie .pth`, and we used to define the model by instantiating the class `LeNet` and then loading the `weights` by `LeNet.load_state_dict()`.  \n",
    "However, the `.pt` file is a stand-alone file that contains the necessary information to define the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='green'>Converting from PyTorch to Libtorch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the necessary libraries.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a network in Pytorch\n",
    "class LeNet(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.feature = nn.Sequential(\n",
    "        #input (28,28,1), #output (24,24,6) formula [(28-5)/1]+1=24\n",
    "        nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5), \n",
    "        nn.ReLU(),\n",
    "         #input (24,24,6), output (12,12,6)\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        #input (12,12,6) output (8,8,16) formula [(12-5)]+1 = 8\n",
    "        nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5), \n",
    "        nn.ReLU(),\n",
    "        #input (8,8,16) output (4,4,16)\n",
    "        nn.MaxPool2d(kernel_size=2) \n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Linear(16*4*4,512), #input(4*4*16) output 512\n",
    "        nn.ReLU(),\n",
    "\n",
    "        nn.Linear(512,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128,10)\n",
    "    )\n",
    "  def forward(self,x):\n",
    "    x = self.feature(x)\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "Model = LeNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the `.pt` model, we can load this in Libtorch and infer on a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an IR of the `LeNet` class and save it as `LeNet.pt`.\n",
    "script_model = torch.jit.script(Model)\n",
    "torch.jit.save(script_model, \"./pytorch-to-libtorch/LeNet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Inferring the LeNet.pt Model in Libtorch</font>\n",
    "\n",
    "For inferring the `.pt` model, we need to write the following C++ code.\n",
    "\n",
    "```C++\n",
    "// Load the model insde the `LeNet`\n",
    "torch::jit::script::Module LeNet = torch::jit::load(\"./LeNet.pt\");\n",
    "                                        \n",
    "// Create a random-input\n",
    "auto input = torch::randn({3, 1, 28, 28});\n",
    "\n",
    "// Create an input of type `torch::jit::IValue` since the model is based on `jit`.\n",
    "std::vector<torch::jit::IValue> jit_input;\n",
    "jit_input.push_back(input);\n",
    "\n",
    "// Call the forward function over the input and convert it into `torch.Tensor`\n",
    "auto output = LeNet.forward(jit_input).toTensor();\n",
    "\n",
    "// Calculate the size of the output.\n",
    "std::cout<<\"Output size is \"<<output.sizes()<<std::endl;\n",
    "```\n",
    "\n",
    "**All the code shown above has been written in a C++ file. Let's run a few bash commands to execute that code. The following code cells will build and run the code in the  CPP file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/pytorch-to-libtorch\n"
     ]
    }
   ],
   "source": [
    "%cd pytorch-to-libtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMakeLists.txt\tLeNet.pt  load_traced_LeNet.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/pytorch-to-libtorch/build\n"
     ]
    }
   ],
   "source": [
    "%cd build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found Torch: /home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch/lib/libtorch.so  \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/pytorch-to-libtorch/build\n"
     ]
    }
   ],
   "source": [
    "! cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target run-traced-model\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/run-traced-model.dir/load_traced_LeNet.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable run-traced-model\u001b[0m\n",
      "[100%] Built target run-traced-model\n"
     ]
    }
   ],
   "source": [
    "!cmake --build . --config Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/pytorch-to-libtorch\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the traced model into Libtorch .\n",
      "Inferring on a random input \n",
      "Output size is [3, 10]\n"
     ]
    }
   ],
   "source": [
    "!./build/run-traced-model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
