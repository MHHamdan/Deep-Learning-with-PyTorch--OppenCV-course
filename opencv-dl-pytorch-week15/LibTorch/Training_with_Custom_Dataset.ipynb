{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Training a CNN classifer to recognize 4 objects.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this notebook, we shall train a CNN to recognize whether an image is a chandelier, motorbike, watch or a laptop.   \n",
    "The dataset is derived from the `Caltech dataset` and consists of roughly 400 images.  \n",
    "We have manually created this subset from the whole dataset.  The whole dataset can be found [here](http://www.vision.caltech.edu/Image_Datasets/Caltech101/).  \n",
    "The data-structure looks like this.  \n",
    "\n",
    "caltech_subset  \n",
    "├── test  \n",
    "│   ├── chandeleir  \n",
    "│   ├── laptop  \n",
    "│   ├── motorbikes  \n",
    "│   └── watch  \n",
    "└── train  \n",
    "    ├── chandelier  \n",
    "    ├── laptop  \n",
    "    ├── motorbikes  \n",
    "    └── watch  \n",
    "\n",
    "As we see, we cannot use any inbuilt `Dataset` class to load the images.  \n",
    "Hence we need to create our own `Dataset` class which will be shown in the next section.  \n",
    "\n",
    "Once we create this class, we will also define a simple `CNN` to train on this data.\n",
    "\n",
    "\n",
    "```C++\n",
    "// Create an alias for functional module as in pytorch `import torch.nn.functional as F`\n",
    "namespace F = torch::nn::functional;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color='green'>Creating a custom Dataset class</font>\n",
    "\n",
    "In Pytorch, we inherit the `torch.utils.data.Dataset` class and override the `__len__` and `__getitem__` for the data-size and indexing a sample respectively.  \n",
    "We also specify the `__init__`  according to our specifications.    \n",
    "Once we have specified the class, we only need to pass this `Dataset` object inside the `torch.utils.data.DataLoader` so that it can handle the data-loading pipeline.\n",
    "\n",
    "Libtorch also follows the exact way, except that the syntax is completely different.\n",
    "\n",
    "\n",
    "In the next cell, we will create a class called `Caltech` inheriting from `torch::data::Dataset`.\n",
    "\n",
    "This will consist of a constructor `Caltech()` whose inputs are three arguments:\n",
    "1. `input_path`- A text file that is consisting of the path to images.\n",
    "2. `output_path`- A text file that is consisting of the labels associated with each corresponding image.\n",
    "\n",
    "3. `Path`- The path to the directory where `train` or `test` exists.\n",
    "\n",
    "The constructor also stores these `image-paths` and corresponding `labels`.\n",
    "\n",
    "\n",
    "The function `size()` (equivalent to `__len__`) is overrided to get the total number of samples.\n",
    "\n",
    "The function `get(int index)` (equivalent to `__getitem__`) is overridden to fetch the input image and the corresponding label (in the form of a data-structure `Example`) at a particular index.\n",
    "\n",
    "The text files to the arguments `input_path` and `output_path` have been created explicitly by a different program.\n",
    "Each class is associated with a particular label to is. The mapping is as follows.  \n",
    "`chandeleir - 0, laptop - 1, motorbike - 2, watch - 3` \n",
    "\n",
    "``` C++\n",
    "class Caltech : public torch::data::Dataset<Caltech>\n",
    "    private:\n",
    "        std::vector<std::string>image_paths;// to store the image-paths\n",
    "        std::vector<int>labels; // to store the corresponding labels\n",
    "        std::string data_path; // the path to the dataset\n",
    "        torch::Tensor tensor_, target_; // to return the tensor and label\n",
    "\n",
    "        std::string join_paths(std::string head, const std::string& tail) \n",
    "        {\n",
    "        if (head.back() != '/') {\n",
    "            head.push_back('/');\n",
    "        }\n",
    "        head += tail;\n",
    "        return head;\n",
    "        }\n",
    "\n",
    "    public:\n",
    "        // Create a constructor.\n",
    "        explicit Caltech(const std::string& input_path, const std::string& output_path, const std::string& Path) \n",
    "     { \n",
    "\n",
    "            data_path = Path;\n",
    "            // Read the image paths and store them inside `image_paths`\n",
    "            std::ifstream file1(input_path);\n",
    "            std::string curline1;\n",
    "            while (std::getline(file1, curline1))\n",
    "            {\n",
    "                image_paths.push_back(curline1);\n",
    "            }\n",
    "            file1.close();  \n",
    "\n",
    "            // Read the labels and store them inside `labels`\n",
    "            std::ifstream file2(output_path);\n",
    "            std::string curline2;\n",
    "            while (std::getline(file2, curline2))\n",
    "            {\n",
    "                labels.push_back(std::stoi(curline2));\n",
    "            }\n",
    "            file2.close();  \n",
    "\n",
    "    }\n",
    "\n",
    "    /// Returns the length of the samples.\n",
    "    torch::optional<size_t> size() const override\n",
    "    { return image_paths.size(); }\n",
    "\n",
    "    /// Returns a pair of input-Tensor and correspoiding Label  at the given `index`.\n",
    "    torch::data::Example<> get(size_t index) override\n",
    "    {\n",
    "        // read the image path at a given index\n",
    "        cv::Mat image = cv::imread(join_paths(data_path, image_paths[index]));\n",
    "        cv::resize(image, image ,cv::Size(160, 160));\n",
    "        // convert from cv::Mat to torch::Tensor\n",
    "        torch::Tensor tensor_ = torch::from_blob(image.data, {image.rows, image.cols, 3}, at::kByte);\n",
    "        tensor_ = tensor_.toType(at::kFloat);\n",
    "        tensor_ = tensor_.permute({2, 0, 1});\n",
    "        // store the corresponding label at a articular index.\n",
    "        torch::Tensor target_ = torch::tensor(labels[index]);\n",
    "\n",
    "        return { tensor_, target_ };\n",
    "    }\n",
    "\n",
    " };\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  <font color='green'>Create a simple CNN</font>\n",
    "\n",
    "``` C++\n",
    "struct Net : torch::nn::Module\n",
    "{\n",
    "    Net(int64_t num_classes)    \n",
    "    {\n",
    "        // register the parameters of the model\n",
    "        conv1_1 = register_module(\"conv1_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(3, 32, 3).padding(1)));\n",
    "        conv1_2 = register_module(\"conv1_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(32, 32, 3)));\n",
    "        dp1 = register_module(\"dp1\", torch::nn::Dropout(0.25));\n",
    "        conv2_1 = register_module(\"conv2_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(32, 64, 3).padding(1)));\n",
    "        conv2_2 = register_module(\"conv2_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3)));\n",
    "        dp2 = register_module(\"dp2\", torch::nn::Dropout(0.25));\n",
    "        conv3_1 = register_module(\"conv3_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3).padding(1)));\n",
    "        conv3_2 = register_module(\"conv3_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(64, 64, 3)));\n",
    "        dp3 = register_module(\"dp3\", torch::nn::Dropout(0.25));\n",
    "        fc1 = register_module(\"fc1\", torch::nn::Linear(2 * 2 * 64 * 81, 512));\n",
    "        dp4 = register_module(\"dp4\", torch::nn::Dropout(0.5));\n",
    "        fc2 = register_module(\"fc2\", torch::nn::Linear(512, num_classes));\n",
    "    }\n",
    "    // the forward function to guide the flow of tensors.\n",
    "    torch::Tensor forward(torch::Tensor x)\n",
    "    {\n",
    "        x = torch::relu(conv1_1->forward(x));\n",
    "        x = torch::relu(conv1_2->forward(x));\n",
    "        x = torch::max_pool2d(x, 2);\n",
    "        x = dp1(x);\n",
    "\n",
    "        x = torch::relu(conv2_1->forward(x));\n",
    "        x = torch::relu(conv2_2->forward(x));\n",
    "        x = torch::max_pool2d(x, 2);\n",
    "        x = dp2(x);\n",
    "        \n",
    "        x = torch::relu(conv3_1->forward(x));\n",
    "        x = torch::relu(conv3_2->forward(x));\n",
    "        x = torch::max_pool2d(x, 2);\n",
    "        x = dp3(x);\n",
    "\n",
    "        x = x.view({-1, 2 * 2 * 64 * 81});\n",
    "        \n",
    "        x = torch::relu(fc1->forward(x));\n",
    "        x = dp4(x);\n",
    "        x = torch::log_softmax(fc2->forward(x), 1);\n",
    "        \n",
    "        return x;\n",
    "    }\n",
    "    // initializing the layers.\n",
    "    torch::nn::Conv2d conv1_1{nullptr};\n",
    "    torch::nn::Conv2d conv1_2{nullptr};\n",
    "    torch::nn::Conv2d conv2_1{nullptr};\n",
    "    torch::nn::Conv2d conv2_2{nullptr};\n",
    "    torch::nn::Conv2d conv3_1{nullptr};\n",
    "    torch::nn::Conv2d conv3_2{nullptr};\n",
    "    torch::nn::Dropout dp1{nullptr};\n",
    "    torch::nn::Dropout dp2{nullptr};\n",
    "    torch::nn::Dropout dp3{nullptr};\n",
    "    torch::nn::Dropout dp4{nullptr};\n",
    "    torch::nn::Linear fc1{nullptr};\n",
    "    torch::nn::Linear fc2{nullptr};\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color='green'> Creating functions for training and testing on every epoch</font>\n",
    "\n",
    "``` C++\n",
    "// create a template function for training.\n",
    "// this function is called for every epoch.\n",
    "template <typename DataLoader>\n",
    "void train(int32_t epoch, Net& model, torch::Device device, DataLoader& data_loader, torch::optim::Optimizer& optimizer, size_t dataset_size)\n",
    "{   // Port the model to training mode.\n",
    "    model.train();\n",
    "    double train_loss = 0;\n",
    "    int32_t correct = 0;\n",
    "    size_t batch_idx = 0;  \n",
    "    // iterate for every batch in the dataset\n",
    "    for (auto& batch : data_loader) {\n",
    "        auto x = batch.data.to(device), targets = batch.target.to(device);\n",
    "        optimizer.zero_grad();\n",
    "        auto output = model.forward(x);\n",
    "        // calcculate the loss\n",
    "        auto loss = F::cross_entropy(output, targets);\n",
    "        AT_ASSERT(!std::isnan(loss.template item<float>()));\n",
    "        // calculate the gradients and update the parameters\n",
    "        loss.backward();\n",
    "        optimizer.step();\n",
    "        // get the accuracy \n",
    "        train_loss += loss.template item<float>();\n",
    "        auto pred = output.argmax(1);\n",
    "        correct += pred.eq(targets).sum().template item<int64_t>();\n",
    "        batch_idx+=1;       \n",
    "    }\n",
    "    train_loss /= batch_idx;\n",
    "    std::printf(\n",
    "        \"\\n   Train set: Average loss: %.4f | Accuracy: %.3f\",\n",
    "        train_loss,\n",
    "        static_cast<double>(correct) / dataset_size);\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "``` C++\n",
    "// create a template function for testing.\n",
    "// this function is called for every epoch.\n",
    "template <typename DataLoader>\n",
    "void test(Net& model, torch::Device device, DataLoader& data_loader, size_t dataset_size)\n",
    "{\n",
    "    // pytorch equivalent of with `torch.no_grad()`\n",
    "    torch::NoGradGuard no_grad;\n",
    "    // Port the model to evaluation mode.\n",
    "    model.eval();\n",
    "    double test_loss = 0;\n",
    "    int32_t correct = 0;\n",
    "    // iterate over every batch in the dataset\n",
    "    for (const auto& batch : data_loader) {\n",
    "        auto data = batch.data.to(device), targets = batch.target.to(device);\n",
    "        auto output = model.forward(data);\n",
    "        // Calculate the loss\n",
    "        test_loss += F::cross_entropy(\n",
    "            output,\n",
    "            targets,\n",
    "            F::CrossEntropyFuncOptions().ignore_index(-100).reduction(torch::kSum))\n",
    "            .template item<float>();\n",
    "        // calculate the accuracy\n",
    "        auto pred = output.argmax(1);\n",
    "        correct += pred.eq(targets).sum().template item<int64_t>();\n",
    "    }\n",
    "\n",
    "    test_loss /= dataset_size;\n",
    "    std::printf(\n",
    "        \"\\n    Test set: Average loss: %.4f | Accuracy: %.3f\\n\",\n",
    "        test_loss,\n",
    "        static_cast<double>(correct) / dataset_size);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> Code inside the \"main\" Function </font>\n",
    "\n",
    "``` C++\n",
    "// declare global variables\n",
    "int numEpochs = 8; // number of epochs\n",
    "int trainBatchSize = 32; // batch size of training data\n",
    "int testBatchSize = 16; // batch size of test data\n",
    "\n",
    "// check if gpu is available\n",
    "torch::DeviceType device_type;\n",
    "if (torch::cuda::is_available()) {\n",
    "    std::cout << \"CUDA available! Training on GPU.\" << std::endl;\n",
    "    device_type = torch::kCUDA;\n",
    "}\n",
    "else {\n",
    "    std::cout << \"Training on CPU.\" << std::endl;\n",
    "    device_type = torch::kCPU;\n",
    "}\n",
    "torch::Device device(device_type);\n",
    "\n",
    "// instantiate a model called `CaltechClassifier` and push it to device. (gpu or cpu)\n",
    "Net CaltechClassifier(4);\n",
    "CaltechClassifier.to(device);\n",
    "```\n",
    "\n",
    "```C++\n",
    "// Setting the necessary attributes to a tensor.\n",
    "auto options = torch::TensorOptions().dtype(torch::kFloat64)//.device(torch::kCPU,1);\n",
    "        \n",
    "// Initialize the `Caltech` dataset with respective paths for both train and test data.\n",
    " \n",
    "auto trainData = Caltech(\"./caltech_subset/train_paths.txt\",\"./train_labels.txt\", \"./caltech_subset/train\").map(torch::data::transforms::Stack<>());\n",
    "auto testData = Caltech(\"./caltech_subset/test_paths.txt\", \"./test_labels.txt\", \"./caltech_subset/test\").map(torch::data::transforms::Stack<>());\n",
    "```\n",
    "\n",
    "```C++\n",
    "// create the `DataLoader` for training as well as testing data.\n",
    "auto trainDataloader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(trainData, trainBatchSize);\n",
    "auto testDataloader = torch::data::make_data_loader<torch::data::samplers::RandomSampler>(testData, testBatchSize);\n",
    "\n",
    "// Get the number of samples in training data as well as test-data\n",
    "const int64_t trainLen = trainData.size().value();\n",
    "const int64_t testLen = testData.size().value();\n",
    "\n",
    "// create an optimizer `Adam` with the parameters of the model to optimize.\n",
    "// We will use beta1 as 0.5 and beta2 as 0.9, with learning-rate of 0.0002\n",
    "torch::optim::Adam optimizer(CaltechClassifier.parameters(), torch::optim::AdamOptions(2e-4).betas(std::make_tuple(0.5,0.9)));\n",
    "                ```\n",
    "\n",
    "```C++\n",
    "// for every epoch call the train function as well as the test function.\n",
    "for (size_t epoch = 1; epoch <= numEpochs; ++epoch) \n",
    "{\tstd::cout<<\"Epoch \"<<epoch<<\" statistics.\"<<std::endl;\n",
    "    train(epoch, CaltechClassifier, device, *trainDataloader, optimizer, trainLen);\n",
    "    test(CaltechClassifier, device, *testDataloader, testLen);\n",
    "}\n",
    "```\n",
    "\n",
    "**All the code shown above has been written in a C++ file. Let's run a few bash commands to execute that code. The following code cells will build and run the code in the CPP file.**\n",
    "\n",
    "Note that we shall use the `OpenCV` C++ library to read images.  \n",
    "Hence we need to mention the path to the cmake files of OpenCV.  \n",
    "\n",
    "Essentially, we need to set the path where the files `OpenCVConfig.cmake`, `OpenCVModules.cmake`, `OpenCVConfig-version.cmake` , `OpenCVModules-release.cmake` are present.  \n",
    "In my desktop, these are present at `/home/chetan/cv2/OpenCV/lib/cmake/opencv4`.  \n",
    "\n",
    "Therefore you need to set this path manually in `CMakeLists.txt` in the place  \n",
    "`find_package(OpenCV REQUIRED PATHS \"path/to/opencv/cmake-files\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch-train-cnn\n"
     ]
    }
   ],
   "source": [
    "%cd libtorch-train-cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caltech_subset\tCaltech_training.cpp  CMakeLists.txt  run_training.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch-train-cnn/build\n"
     ]
    }
   ],
   "source": [
    "%cd build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 7.5.0\n",
      "-- The CXX compiler identification is GNU 7.5.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found Torch: /home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch/lib/libtorch.so  \n",
      "-- Found OpenCV: /home/chetan/cv2/OpenCV (found version \"4.3.0\") \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch-train-cnn/build\n"
     ]
    }
   ],
   "source": [
    "!cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target Libtorch-week15-trainCNN\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/Libtorch-week15-trainCNN.dir/Caltech_training.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable Libtorch-week15-trainCNN\u001b[0m\n",
      "[100%] Built target Libtorch-week15-trainCNN\n"
     ]
    }
   ],
   "source": [
    "!cmake --build . --config Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chetan/projects/piethon/pth_course/c3_w15_dl_pytorch/LibTorch/libtorch-train-cnn\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU.\n",
      "Epoch 1 statistics.\n",
      "   Train set: Average loss: 1.9607 | Accuracy: 0.287\n",
      "   Test set: Average loss: 1.3588 | Accuracy: 0.522\n",
      "Epoch 2 statistics.\n",
      "   Train set: Average loss: 1.2910 | Accuracy: 0.408\n",
      "   Test set: Average loss: 1.1972 | Accuracy: 0.500\n",
      "Epoch 3 statistics.\n",
      "   Train set: Average loss: 1.0302 | Accuracy: 0.576\n",
      "   Test set: Average loss: 0.9109 | Accuracy: 0.717\n",
      "Epoch 4 statistics.\n",
      "   Train set: Average loss: 0.6811 | Accuracy: 0.735\n",
      "   Test set: Average loss: 1.0157 | Accuracy: 0.565\n",
      "Epoch 5 statistics.\n",
      "   Train set: Average loss: 0.5266 | Accuracy: 0.818\n",
      "   Test set: Average loss: 0.3735 | Accuracy: 0.913\n",
      "Epoch 6 statistics.\n",
      "   Train set: Average loss: 0.4325 | Accuracy: 0.834\n",
      "   Test set: Average loss: 0.2998 | Accuracy: 0.913\n",
      "Epoch 7 statistics.\n",
      "   Train set: Average loss: 0.3048 | Accuracy: 0.887\n",
      "   Test set: Average loss: 0.7111 | Accuracy: 0.696\n",
      "Epoch 8 statistics.\n",
      "   Train set: Average loss: 0.3518 | Accuracy: 0.866\n",
      "   Test set: Average loss: 0.3403 | Accuracy: 0.848\n"
     ]
    }
   ],
   "source": [
    "!./build/Libtorch-week15-trainCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'> References </font>\n",
    "\n",
    "1. http://www.vision.caltech.edu/Image_Datasets/Caltech101/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
