{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> ONNX - Open Neural Network Exchange</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/09/c3-w15-onnx.png\" height=\"500\">\n",
    "\n",
    "---\n",
    "\n",
    "ONNX, as the name says, is a platform for exchanging the formats `(.pth(Pytorch), .pb(TensorFlow), etc.)` of Neural Networks.\n",
    "\n",
    "**Why do we need ONNX?**\n",
    "\n",
    "Often, the training environment (Python) is different from the production environment (Java, C#, etc.), and these models need to be deployed. \n",
    "\n",
    "Since we have trained the models in either any of the Deep Learning frameworks,  we somehow want to port this model for serving. And this is where ONNX appears to be pretty handy.\n",
    "\n",
    "\n",
    "Sometimes, we might also need to switch the model between frameworks ie, from `Pytorch to MXNET` or from `Keras to Pytorch`, etc., and ONNX can help us here too.\n",
    "\n",
    "We also need to note that every framework has its way of storing the weights ie, Keras saves the model-weights as a `.h5` file, Pytorch just stores the weights in a `.pth` file, so we need a way to store the weights such that all the frameworks can recognize it. \n",
    "\n",
    "## <font color='blue'>Installations</font>\n",
    "\n",
    "Before we start, we need to install the required dependencies. So let's start with installation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx # to load the onnx model\n",
    "!pip install onnxruntime # to load the onnx model\n",
    "!pip install onnx2keras # to convert an onnx-model to keras-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>1. PyTorch to ONNX</font>\n",
    "\n",
    "PyTorch provides us a very easy-to-use function to convert a PyTorch model to an ONNX format ending with an extension `.onnx`.\n",
    "\n",
    "Let's go ahead and see how we can do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to import the necessary libraries\n",
    "import onnx \n",
    "import onnxruntime\n",
    "import torch\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the PyTorch model:  tensor(-3.2903)\n"
     ]
    }
   ],
   "source": [
    "# Pick a model from torchvision to port it to ONNX.\n",
    "# We shall use the `resnet18()` to port it to ONNX.\n",
    "resnet = models.resnet18()\n",
    "\n",
    "# Place the model in `evaluation-mode`\n",
    "resnet.eval()\n",
    "# Create a random input and get the output\n",
    "ip = torch.randn(1,3, 224, 224)\n",
    "with torch.no_grad():\n",
    "    op = resnet(ip)\n",
    "\n",
    "# Lets take the output-summation to see if we get the same output inferring through ONNX too\n",
    "print(\"The output from the PyTorch model: \",op.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We shall convert the Pytorch model to ONNX using the function below.\n",
    "torch.onnx.export(resnet, ip, \"resnet.onnx\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font color='green'>2. Inferring in ONNX</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to create a session for inference when running an onnx model.\n",
    "session = onnxruntime.InferenceSession(\"resnet.onnx\")\n",
    "\n",
    "# We also need to get the input_name. \n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "## Run the session be specifying our input at the node `input_name` and specifying that\n",
    "## we need to break the graph at the node `output_name`\n",
    "result = session.run([output_name], {input_name: ip.numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the ONNX model:  -3.2903175\n"
     ]
    }
   ],
   "source": [
    "## The `result` will be a list since we passed the outputs in the form of a list.\n",
    "print(\"The output from the ONNX model: \",result[0].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>3. Inferring in OpenCV</font>\n",
    "\n",
    " Often, the production environment is constrained to only a few libraries. And we cannot afford to use the `Pytorch` library, since we need it to only infer on the input.\n",
    " \n",
    "Hence, we need a way to load this `PyTorch` model into existing libraries, and one such library is `OpenCV`. \n",
    "\n",
    "Although the latest version of `OpenCV` already has support to load models from `TensorFlow`,  `Caffe`, etc., we don't have an API for loading `PyTorch` models. And, guess what, ONNX comes to our rescue here.\n",
    "\n",
    "In the following cell, we shall see how we can load the converted PyTorch model in OpenCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the opencv library\n",
    "import cv2\n",
    "\n",
    "# use the `readNetFromONNX` API to load the saved-onnx-model.\n",
    "lenet_onnx = cv2.dnn.readNetFromONNX(\"resnet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output from the ONNX model when loaded via OpenCV:  -3.2903004\n"
     ]
    }
   ],
   "source": [
    "# we shall set the input to the network\n",
    "lenet_onnx.setInput(ip.numpy())\n",
    "\n",
    "# get the output of model by calling the `forward()` method.\n",
    "onnx_op = lenet_onnx.forward()\n",
    "\n",
    "# let's verify the sum of this output with the previous results.\n",
    "print(\"The output from the ONNX model when loaded via OpenCV: \", onnx_op.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>4. ONNX to Keras and Inferring in Keras</font>\n",
    "\n",
    "Sometimes, the production environment requires us to have a Tensorflow-based environment.  \n",
    "\n",
    "In that case, too, we can use the module `onnx2keras` to convert from `ONNX` to `Keras` and then save this model to the Keras format `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the onnx_to_keras function\n",
    "from onnx2keras import onnx_to_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the onnx-model converted from pytorch.\n",
    "onnx_model = onnx.load(\"resnet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we shall specify the required arguments to the function. The argument `change_ordering` \n",
    "# makes the model portable to input shape (B, H, W, C).\n",
    "\n",
    "keras_model = onnx_to_keras(onnx_model=onnx_model, input_names=[input_name], change_ordering=True)\n",
    "# this `keras_model` is now the Resnet-graph built in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sum when converting from ONNX to Keras:  -3.2902946\n"
     ]
    }
   ],
   "source": [
    "# We can now use this graph to verify if we get the same results.\n",
    "\n",
    "# We should use the `predict()` method to call the evaluation-mode.\n",
    "# Also note that, the input is permuted from [B, C, H, W] to [B, H, W, C].\n",
    "\n",
    "keras_op = keras_model.predict(ip.permute(0, 2, 3, 1).numpy())\n",
    "print(\"Output sum when converting from ONNX to Keras: \", keras_op.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
